---
title: "Virus detection in Cassava SRA `r params$SRA`"
author: "Marco Chiapello"
date: "28/04/2021"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_float:
      toc_collapsed: true
    toc_depth: 3
    number_sections: true
    theme: lumen
params:
  SRA: PRJNA306864
  sratoolkit: "/Users/raffaella/Desktop/bioutils/sratoolkit.2.11.0-mac64/bin/fasterq-dump"
  star: "/ME4/massimo/software/STAR-2.7.8a/bin/Linux_x86_64/STAR"
  bbtools: "/ME4/massimo/software/bbmap/"
  trinity: "/ME4/massimo/software/trinityrnaseq-v2.12.0/Trinity"
---

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(fs)
library(tidyverse)
library(DT)
library(biomartr)
library(here)
setwd(here())

# params <- NULL
# params$SRA <- "PRJNA306864"
# params$sratoolkit <-  "/home/massimo/sratoolkit.2.9.6-1-ubuntu64/bin/fasterq-dump"
# params$bbtools <-  "/ME4/massimo/software/bbmap/"
# params$star <- "/ME4/massimo/software/STAR-2.7.8a/bin/Linux_x86_64/STAR"
# params$trinity <- "/ME4/massimo/software/trinityrnaseq-v2.12.0/Trinity"
# params$trinity <- "/usr/share/trinity291/Trinity"
```

# Download needed data

## Download Cassava genome

_Manihot esculenta_ genome has been downloaded from NCBI RefSeq dataset. 

Here all the information about the downloaded genome: 

```{r warning=FALSE, message=FALSE}
if(file_exists("_ncbi_downloads/genomes/Manihot_esculenta_genomic_refseq.fna")){
  suME <- read_tsv("_ncbi_downloads/genomes/doc_Manihot_esculenta_db_refseq.txt") %>%
    separate(`File Name: Manihot_esculenta_genomic_refseq.fna.gz`, into = c("Data", "Info"), sep = ": ")
} else {
  ME.genome.refseq <- getGenome(db       = "refseq", 
                                organism = "Manihot esculenta")
  suME <- read_tsv("_ncbi_downloads/genomes/doc_Manihot_esculenta_db_refseq.txt") %>%
    separate(`File Name: Manihot_esculenta_genomic_refseq.fna.gz`, into = c("Data", "Info"), sep = ": ")
}

datatable(suME)

```

### Table of SRA matadata

```{r warning=FALSE, message=FALSE}
# Build the link to download metadata file
system(paste(
  "wget 'http://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?save=efetch&rettype=runinfo&db=sra&term=", params$SRA,
  "' -O ", "data/", params$SRA, "/SraMetadata_", params$SRA,
  sep = ""))

SRA_meta <- read_csv(paste("./data/", params$SRA, "/SraMetadata_", params$SRA, sep = ""))

datatable(SRA_meta)
```

### List of downloaded SRA

```{r warning=FALSE, message=FALSE}
# Create SRA folder if it does not exist
if(!file_exists(paste0("mkdir -p data/", params$SRA))){
  system(paste0("mkdir -p data/", params$SRA))
}

# Check the presence of SRA already downloaded
f <- tibble(system = str_remove(basename(dir_ls(paste0("data/", params$SRA), 
                                                regex = "fastq$")), ".fastq.gz"))


SRA_meta2 <- SRA_meta %>%
    mutate(ID = Run) %>%
    group_by(ID) %>%
    nest()

# Function to dowload SRA Run
downFastq <- function(x){
    if(x$LibraryLayout == "SINGLE"){
        system(paste0(
          params$sratoolkit, " -e 30 -p ", x$Run,
          " -O data/", params$SRA))
    }
    if(x$LibraryLayout == "PAIRED"){
        system(paste0(
          params$sratoolkit, " -e 30 -p --split-files ", x$Run,
          " -O data/", params$SRA))
    }
}

# Download SRA Run
map(SRA_meta2$data, downFastq)

datatable(tibble(system = dir_ls(paste0("data/", params$SRA), regex = "fastq$")),
	rownames = FALSE,
    filter = "top",
    extensions = 'Buttons',
    options = list(dom = 'Brtip',
                     buttons = c('csv', 'copy')))
```

### Reads alignment

#### Pre-alignment sketch

To perform sketch we used [BBTools](https://jgi.doe.gov/data-and-tools/bbtools/).

BBTools is a suite of fast, multithreaded bioinformatics tools designed for analysis of DNA and RNA sequence data. BBTools can handle common sequencing file formats such as fastq, fasta, sam, scarf, fasta+qual, compressed or raw, with autodetection of quality encoding and interleaving. It is written in Java and works on any platform supporting Java, including Linux, MacOS, and Microsoft Windows and Linux; there are no dependencies other than Java (version 7 or higher). Program descriptions and options are shown when running the shell scripts with no parameters.

BBTools is open source and free for unlimited use, and is used regularly by DOE JGI and other institutions around the world.

```{r warning=FALSE, message=FALSE}
# Read file path
f <- dir_ls(paste0("data/", params$SRA), regex = "fastq$")

########################################
# Create sketch on the original reads
if (!file_exists(paste0("data/", params$SRA, "/preSketchOK"))){
    for (i in f){
        system(paste0(params$bbtools,"sendsketch.sh in=", i,
                      " out=", str_replace(i, "fastq", "sketchOriginal"), ".tsv reads=1000000 ",
                      "  minprob=0.2 samplerate=1.0 merge printname0=f ", 
                      " records=20 overwrite=true color=false depth depth2",
                      " unique2 volume printscore contam2=genus nt ow" ))
    }
}

file_create(paste0("data/", params$SRA, "/preSketchOK"))

# Parse output
so <- map_df(dir_ls(paste0("data/", params$SRA), regex = "sketchOriginal"),
          read_delim, delim = "\t", .id = "SRA", skip = 2) %>% 
    mutate(SRA = str_remove(SRA, paste0("data/", params$SRA, "/")),
           SRA = str_remove(SRA, ".sketchOriginal.tsv")) %>%
    group_by(SRA) %>%
    mutate(N = row_number())


datatable(so,
	rownames = FALSE,
    filter = "top",
    extensions = 'Buttons',
    options = list(dom = 'Brtip',
                     buttons = c('csv', 'copy')))
```

**Meaning of Columns**

**WKID**:     Weighted Kmer IDentity, which is the kmer identity compensating for differences in size.  So, comparing human chr1 to the full human genome would yield 100% WKID but approximately 10% KID.    
**KID**:      Kmer IDentity, equal to matches/length; this is the fraction of shared kmers.     
**ANI**:      Average Nucleotide Identity, derived from WKID and kmer length.     
**Complt**:   Genome completeness (percent of the reference represented in the query).  Derived from WKID and KID.     
**Contam**:   Contamination (percent of the query that does not match this reference, but matches some other reference).     
**Depth**:    Estimated genomic kmer coverage depth based on the average number of occurences of kmers in query sketch for those kmers matching the reference sketch.     
**Depth2**:   Depth compensated for repeat kmers in the reference genome.     
**Volume**:   Sum of query counts of shared kmers, equal to the number of total (rather than unique) reference kmers that occured in the query sequence, divided by 1000      (for formatting).
**Matches**:  The number of shared kmers between query and ref.     
**Unique**:   The number of shared kmers between query and ref, and no other ref.     
**TaxID**:    NCBI taxonomic id, when available.     
**gSize**:    Estimate of genomic size (number of unique kmers in the genome).  This is based on the smallest hash value in the list.  This is affected by blacklists or whitelists, entropy, and by using an assembly versus raw reads.     
**gSeqs**:    Number of sequences used in the sketch.     
**TaxName**:  NCBI's name for that taxID.  If there is no taxID, the sequence name will be used.     


#### Remove Cassava genome


```{r warning=FALSE, message=FALSE}
########################################
# Remove Cassava genome
if (!file_exists(paste0("data/", params$SRA, "/genomeIndexOK"))){
    # Genome index
    system(paste0(params$star,
                  " --runThreadN 20 --runMode genomeGenerate --genomeDir ",
                  "_ncbi_downloads/manihot_esculenta_index/ --genomeFastaFiles ",
                  "_ncbi_downloads/genomes/Manihot_esculenta_genomic_refseq.fna ",
                  "--genomeSAindexNbases 13"))
}
file_create(paste0("data/", params$SRA, "/genomeIndexOK"))

    # Genome Removal
if (!file_exists(paste0("data/", params$SRA, "/genomeRemovalOK"))){
    for (file in f){
        system(paste0(params$star, " --runThreadN 30 --genomeDir ",
              "_ncbi_downloads/manihot_esculenta_index/ --readFilesIn ",
                file, "  --outFileNamePrefix data/", params$SRA, "/",
                str_split(basename(file), '.fastq')[[1]][1],
                " --outReadsUnmapped Fastx"))
    }
    del <- dir_ls(paste0(paste0("data/", params$SRA, "/")),
                  regex = "SJ.out.tab$|Aligned.out.sam$|Log")
    file_delete(del)
}
file_create(paste0("data/", params$SRA, "/genomeRemovalOK"))

mf <- dir_ls(paste0("data/", params$SRA, "/"), regex = "out.mate1$")
file_move(mf, str_replace(mf, "out.mate1", "fasta"))

########################################
# Create sketch
f <- dir_ls(paste0("data/", params$SRA), regex = "Unmapped")

if(!file_exists(paste0("data/", params$SRA, "/postSketchOK"))){
    for (i in f){
        system(paste0(params$bbtools,"sendsketch.sh in=", i,
                      " out=", str_replace(i, "fastq$", "sketchUnmap"), ".tsv reads=1000000 ",
                      "  minprob=0.2 samplerate=1.0 merge printname0=f ", 
                      " records=20 overwrite=true color=false depth depth2",
                      " unique2 volume printscore contam2=genus nt ow" ))
    }
}

file_create(paste0("data/", params$SRA, "/postSketchOK"))

su <- map_df(dir_ls(paste0("data/", params$SRA), regex = "Unmapped.out.mate1.tsv$"),
          read_delim, delim = "\t", .id = "SRA", skip = 2) %>% 
    mutate(SRA = str_remove(SRA, paste0("data/", params$SRA, "/")),
           SRA = str_remove(SRA, ".sketchOriginal.tsv")) %>%
    group_by(SRA) %>%
    mutate(N = row_number())

datatable(su,
	rownames = FALSE,
    filter = "top",
    extensions = 'Buttons',
    options = list(dom = 'Brtip',
                     buttons = c('csv', 'copy')))
```

**Meaning of Columns**

**WKID**:     Weighted Kmer IDentity, which is the kmer identity compensating for differences in size.  So, comparing human chr1 to the full human genome would yield 100% WKID but approximately 10% KID.    
**KID**:      Kmer IDentity, equal to matches/length; this is the fraction of shared kmers.     
**ANI**:      Average Nucleotide Identity, derived from WKID and kmer length.     
**Complt**:   Genome completeness (percent of the reference represented in the query).  Derived from WKID and KID.     
**Contam**:   Contamination (percent of the query that does not match this reference, but matches some other reference).     
**Depth**:    Estimated genomic kmer coverage depth based on the average number of occurences of kmers in query sketch for those kmers matching the reference sketch.     
**Depth2**:   Depth compensated for repeat kmers in the reference genome.     
**Volume**:   Sum of query counts of shared kmers, equal to the number of total (rather than unique) reference kmers that occured in the query sequence, divided by 1000      (for formatting).
**Matches**:  The number of shared kmers between query and ref.     
**Unique**:   The number of shared kmers between query and ref, and no other ref.     
**TaxID**:    NCBI taxonomic id, when available.     
**gSize**:    Estimate of genomic size (number of unique kmers in the genome).  This is based on the smallest hash value in the list.  This is affected by blacklists or whitelists, entropy, and by using an assembly versus raw reads.     
**gSeqs**:    Number of sequences used in the sketch.     
**TaxName**:  NCBI's name for that taxID.  If there is no taxID, the sequence name will be used.     

# TRINITY

## Prepare sample file 

```{r warning=FALSE, message=FALSE}
# Trinity out_file input file creation
out_file <- paste("data/",params$SRA,"/trinity_samples", sep = "") 

# Path to files
fileNames <- dir_ls(paste0("data/", params$SRA), regex = "Unmapped.fasta$")

##### WRITE CONDITION FOR SINGLE ENDED
# write single end runs to out_file
df <- tibble(X1 = SRA_meta2$ID,
       X2 = paste0(SRA_meta2$ID, '_rep1'),
       X3 = fileNames[grepl("_1Unmapped", base::basename(fileNames))],
       X4 = fileNames[grepl("_2Unmapped", base::basename(fileNames))])


write.table(df, out_file, append = FALSE, sep = "\t", dec = ".",
            row.names = FALSE, col.names = FALSE, quote = FALSE)
```

## Run Assembly

```{r warning=FALSE, message=FALSE}
# trinity command execution 
if(!file_exists(paste0("data/", params$SRA, "/trinityOK"))){
    system(paste0(params$trinity, " --seqType fq --samples_file ", out_file,
                  " --CPU 20 --trimmomatic --no_normalize_reads --full_cleanup ",
                  " --min_contig_length 1000 --max_memory 200G --output ",
                  " data/",params$SRA,"/trinity_out_dir" ))
}

file_create(paste0("data/", params$SRA, "/trinityOK"))

# Create summary table
or <- dir_ls(paste0("data/", params$SRA), regex = "fastq$")
ur <- dir_ls(paste0("data/", params$SRA), regex = "Unmapped.fasta$")
tr <- dir_ls(paste0("data/", params$SRA), regex = "trinity_out_dir.Trinity.fasta$")
tr2 <- as.numeric(system(paste0("grep -c '>' ", tr), intern = TRUE))

  or2 <- vector()
  for (i in seq_along(or)){
      or2[i] <- as.numeric(system(paste0("grep -c '@' ", or[i]),
                                  intern = TRUE))
  }


ur2 <- vector()
for (i in seq_along(ur)){
    ur2[i] <- as.numeric(system(paste0("grep -c '@' ", ur[i]),
                                intern = TRUE))
}

assDF <- tibble(Reads = str_remove(or, paste0("data/", params$SRA, "/")),
                Original = or2,
                Unmapped = ur2) %>%
    mutate(Reads = str_remove(Reads, ".fastq"),
           Reduced = (1 - Unmapped / Original) * 100)
```

Unmapped reads led to the identification of `r tr2` contigs longer than 1000bp.

# Produce unicontigs

```{r warning=FALSE, message=FALSE}
if(!file_exists(paste0("data/", params$SRA, "/unicontigOK"))){
    system(paste0("~/cd-hit-v4.8.1-2019-0228/cd-hit-est -i ", tr, " -o ", 
                  paste0("data/", params$SRA), "/uniContig.fasta", " -c 0.9 -M 120000 -T 20"))
}

file_create(paste0("data/", params$SRA, "/unicontigOK"))
```

# Blast against NCBInr

```{r warning=FALSE, message=FALSE}
if(!file_exists(paste0("data/", params$SRA, "/blastOK"))){
    system(paste0("~/diamond blastx -p20 -d /ME4/massimo/DB/nr -q ",
                  " data/", params$SRA, "/uniContig.fasta",
                  " -o data/", params$SRA, "/uniContig.tab",
                  " -f 6 qseqid qlen sseqid stitle slen pident length mismatch gapopen qstart qend sstart send evalue bitscore qcovhsp scovhsp",
                  " -k 5 -e 0.0000000001 --unal 0 --very-sensitive"))
}

file_create(paste0("data/", params$SRA, "/blastOK"))

```

## Parse results

```{r warning=FALSE, message=FALSE}
########################################
# Read data BLAST
if(!file_exists(paste0("data/", params$SRA, "/blastparseOK"))){
    f <- dir_ls(paste0("data/", params$SRA), regex = "uniContig.tab$")
  df <- read_delim(f, delim = "\t", col_names = FALSE)
  names(df) <- c("qseqid", "qlen", "sseqid", "stitle", "slen", "pident", 
                 "length", "mismatch", "gapopen", "qstart", 
                 "qend", "sstart", "send", "evalue", "bitscore",
                 "qcovhsp", "scovhsp")
  
  #Transforn the blast results
  df2 <- df %>%
      separate(stitle, into = c("Desc", "Organism"), sep = "\\[", extra = "merge") %>%
      mutate(Organism = str_remove(Organism, "]"),
             Desc = str_trim(str_remove(Desc, "[^ ]*")),
             Organism = ifelse(grepl("\\[", Organism), str_extract(Organism, "(?<=\\[).+?(?=\\])"),
                               Organism))
  
  ########################################
  # Inspect the 5 blast per query
  ## Function to retrieve the firt match
  ex <- function(x, n = 1){
      x %>%
          arrange(desc(bitscore)) %>%
          dplyr::slice(n)
  }
  
  # Finciotn to retrieve the organism match
  org <- function(x){
      x %>%
          count(Organism, sort = TRUE)
  }
  
  ## Store the data in a nested tibble
  df4 <- df2 %>%
      group_by(qseqid) %>%
      nest() 
  
  ## Extract organisms
  df4o <- df4 %>%
      mutate(sORG = map(data, ~org(.x))) %>%
      unnest(sORG)
  
  ## Extract the first match
  df5 <- df4 %>%
      mutate(FH = map(data, ~ex(.x)))
  # saveRDS(df5, "data/EVA/NCBInrBlastParsedIntermediatResults.RDS")
  
  ## Unnest the first match dataset
  df6 <- df5 %>%
      unnest(FH)
  
  wip <- df2 %>%
      filter(qseqid %in% (df2 %>%
                          filter(grepl("virus|phage", Organism) | grepl("phage", Desc)) %>%
                          pull(qseqid))) %>%
      group_by(qseqid)
  
  library(Biostrings)
  ss <- readDNAStringSet(paste0("data/", params$SRA, "/uniContig.fasta"))
  names(ss) <- str_extract(names(ss), "[^ ]*")
  sdf <- tibble(qseqid = names(ss),
                sequence = as.character(ss))
  
  wip <- wip %>%
      left_join(sdf)
  
  
  ################################################################################
  # Quantification
  ## Create a file with viral contig sequences
  ss2 <- ss[names(ss) %in% unique(wip$qseqid)]
  writeXStringSet(ss2, paste0("data/", params$SRA, "/tomap.fasta"))
  
  ## Run salmon
  system(paste0("/usr/share/trinity291/util/align_and_estimate_abundance.pl",
                " --transcripts ", paste0("data/", params$SRA, "/tomap.fasta"),
                " --seqType fq --samples_file ", 
                paste0("data/",params$SRA,"/trinity_samples"),
                " --est_method salmon --trinity_mode --prep_reference --output_dir ",
                paste0("data/",params$SRA,"/salmon"), "  --thread_count 20"))
  system(paste0("mv *_rep1 data/", params$SRA, "/"))
  
  ## Parse salmon output
  sq <- dir_ls(paste0("data/",params$SRA), recurse = TRUE, regex = "quant.sf$")
  
  sq2 <- map_df(sq, read_tsv, .id = "SRA") %>%
      dplyr::rename(qseqid = Name)
  
    write_tsv(wip, paste0("data/", params$SRA, "/results.fasta"))
}
file_create(paste0("data/", params$SRA, "/blastparseOK"))

wip <- read_tsv(paste0("data/", params$SRA, "/results.fasta"))
datatable(wip,
	rownames = FALSE,
    filter = "top",
    extensions = 'Buttons',
    options = list(dom = 'Brtip',
                     buttons = c('csv', 'copy')))

```

# Orfans


```{r warning=FALSE, message=FALSE}
# f <- paste0("data/", params$SRA, "/uniContig.fasta")
# ################################################################################
# # Read fasta files in and remove the contigs that found a match
# fasta <- readDNAStringSet(f)
# names(fasta) <- str_extract(names(fasta), "[^ ]*")
# 
# um <- fasta[!(names(fasta) %in% unique(df$qseqid))]
# 
# xx <- vmatchPattern(DNAString("TCT"), um, max.mismatch = 1)
# 
# as.data.frame(xx)
```

